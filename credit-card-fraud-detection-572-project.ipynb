{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  Project ","metadata":{}},{"cell_type":"markdown","source":"Outline: \n* intro\n* data\n* data cleaning \n* build model\n* analysis result","metadata":{}},{"cell_type":"markdown","source":"# Introduction\nCredit card have been used a lot in our daily life. However, But credit card fraud has been a long-standing problem, costing both customers and banks a lot of money. In this project, we would like to analyze the credit card fraud data, find any potential pattern of fraud happened, and detect any transactions are fraud. ","metadata":{}},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"markdown","source":"**Acknowledgements**\n\nThe dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection.\nMore details on current and past projects on related topics are available on https://www.researchgate.net/project/Fraud-detection-5 and the page of the DefeatFraud project\n\nPlease cite the following works:\n\nAndrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015\n\nDal Pozzolo, Andrea; Caelen, Olivier; Le Borgne, Yann-Ael; Waterschoot, Serge; Bontempi, Gianluca. Learned lessons in credit card fraud detection from a practitioner perspective, Expert systems with applications,41,10,4915-4928,2014, Pergamon\n\nDal Pozzolo, Andrea; Boracchi, Giacomo; Caelen, Olivier; Alippi, Cesare; Bontempi, Gianluca. Credit card fraud detection: a realistic modeling and a novel learning strategy, IEEE transactions on neural networks and learning systems,29,8,3784-3797,2018,IEEE\n\nDal Pozzolo, Andrea Adaptive Machine learning for credit card fraud detection ULB MLG PhD thesis (supervised by G. Bontempi)\n\nCarcillo, Fabrizio; Dal Pozzolo, Andrea; Le Borgne, Yann-Aël; Caelen, Olivier; Mazzer, Yannis; Bontempi, Gianluca. Scarff: a scalable framework for streaming credit card fraud detection with Spark, Information fusion,41, 182-194,2018,Elsevier\n\nCarcillo, Fabrizio; Le Borgne, Yann-Aël; Caelen, Olivier; Bontempi, Gianluca. Streaming active learning strategies for real-life credit card fraud detection: assessment and visualization, International Journal of Data Science and Analytics, 5,4,285-300,2018,Springer International Publishing\n\nBertrand Lebichot, Yann-Aël Le Borgne, Liyun He, Frederic Oblé, Gianluca Bontempi Deep-Learning Domain Adaptation Techniques for Credit Cards Fraud Detection, INNSBDDL 2019: Recent Advances in Big Data and Deep Learning, pp 78-88, 2019\n\nFabrizio Carcillo, Yann-Aël Le Borgne, Olivier Caelen, Frederic Oblé, Gianluca Bontempi Combining Unsupervised and Supervised Learning in Credit Card Fraud Detection Information Sciences, 2019\n\nYann-Aël Le Borgne, Gianluca Bontempi Machine Learning for Credit Card Fraud Detection - Practical Handbook","metadata":{}},{"cell_type":"markdown","source":"## import packages","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-08-11T17:28:43.163576Z","iopub.execute_input":"2021-08-11T17:28:43.163968Z","iopub.status.idle":"2021-08-11T17:28:43.169127Z","shell.execute_reply.started":"2021-08-11T17:28:43.163930Z","shell.execute_reply":"2021-08-11T17:28:43.167956Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/creditcardfraud/creditcard.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T17:28:45.501815Z","iopub.execute_input":"2021-08-11T17:28:45.502269Z","iopub.status.idle":"2021-08-11T17:28:49.372323Z","shell.execute_reply.started":"2021-08-11T17:28:45.502240Z","shell.execute_reply":"2021-08-11T17:28:49.371531Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Time VS Amount, red - fraud, blue - non-fraud. \nfraud_df = df[df.Class == 1]\nplt.scatter(df.Time, df.Amount, color = 'blue')\nplt.xlabel('Time')\nplt.ylabel('Amount')\n# plt.show()\nplt.scatter(fraud_df.Time, fraud_df.Amount, color = 'red')\nplt.xlabel('Time')\nplt.ylabel('Amount')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# correlation maatrix\n\ncorr = df.corr()\nround(corr,2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(corr);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# look potential statistical distrbution in different features based on fraud or not. \n\nfig, axes = plt.subplots(7, 4, figsize=(24, 16))\nfig.suptitle('Density Plot for each feature')\n\nsns.kdeplot(ax=axes[0,0],x='V1', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[0,1],x='V2', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[0,2],x='V3', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[0,3],x='V4', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[1,0],x='V5', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[1,1],x='V6', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[1,2],x='V7', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[1,3],x='V8', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[2,0],x='V9', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[2,1],x='V10', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[2,2],x='V11', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[2,3],x='V12', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[3,0],x='V13', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[3,1],x='V14', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[3,2],x='V15', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[3,3],x='V16', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[4,0],x='V17', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[4,1],x='V18', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[4,2],x='V19', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[4,3],x='V20', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[5,0],x='V21', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[5,1],x='V22', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[5,2],x='V23', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[5,3],x='V24', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[6,0],x='V25', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[6,1],x='V26', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[6,2],x='V27', hue='Class', data= df, shade=True)\nsns.kdeplot(ax=axes[6,3],x='V28', hue='Class', data= df, shade=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(df.Time.values)\nsns.distplot(fraud_df.Time.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(df.Amount.values)\nsns.distplot(fraud_df.Amount.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.set_theme(style=\"darkgrid\")\nsns.countplot('Class', hue = 'Class', data=df)\nplt.title('Data Class Distributions  \\n (0: No Fraud, 1: Fraud)', fontsize=14)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From above graphs, we find that the values for Time and Amount are in large scale than other 28 features, we need to rescale \"Time\" and \"Amount\" otherwise the model we built may inaccurate. \nMeanwhile, we have also found there is imbalanced class data. The number of fraud transactions are much less than the number of normal transactions. And our object is to detect those fraud credit card transactions, therefore we need to handle these imbalanced data. ","metadata":{}},{"cell_type":"markdown","source":"### Understand the data","metadata":{}},{"cell_type":"markdown","source":"This dataset only contains numerical variables, and due to confidential issues, original features and more background information about the data are removed. The only 28 features V1, V2, ... V28 are the principal components obtained with PCA. Features \"Time\", \"Amount\", \"Class\" are remained the same. Feature \"Class\" is the target variable, it uses 1 to represent fraud and 0 for other cases. Feature \"Amount\" is the transaction amount, and feature \"Time\" is the time difference in seconds between current transaction time and the first transaction time. These two features could help analyze the fraud transaction amount and any seasonal pattern within fraud transactions [1].    \n\n\nThere is no missing value. \nAnd from the plot, we see most fraud transactions do not have the large transaction amount. And it happened during most time stamp. There is no obvious time seasonality trend found. \n\nFrom the corerlation matrix and map, we found there is no obvious co-linear relationship between data features. \n\n\n\n**Reference** \n1. https://www.kaggle.com/mlg-ulb/creditcardfraud\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{}},{"cell_type":"code","source":"# rescale \"Time\" and \"Amount\"\nfrom sklearn.preprocessing import RobustScaler\n\nrobust_scaler = RobustScaler()\ndf['scaled_amount'] = robust_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\ndf['scaled_time'] = robust_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n\ndf.drop(['Time','Amount'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T17:28:54.693698Z","iopub.execute_input":"2021-08-11T17:28:54.694024Z","iopub.status.idle":"2021-08-11T17:28:54.923243Z","shell.execute_reply.started":"2021-08-11T17:28:54.693995Z","shell.execute_reply":"2021-08-11T17:28:54.922297Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data\nfrom sklearn.model_selection import train_test_split \n\n# train, test_ = train_test_split(df, train_size=0.8, random_state=2021, shuffle=True )\n# train_df, validation = train_test_split(train, test_size=0.5, random_state=2021, shuffle=True )\n\nX = df.drop('Class', axis = 1)\ny = df['Class']\ntrain_X,test_X, train_y, test_y = train_test_split(X,y, test_size=0.3, random_state=2021)\n\n# train, validation = train_test_split(train, test_size=0.223, random_state=2021) # 0.777 x 0.9 = 0.7 \n\n# train --> 0.7, validation --> 0.2,  test --> 0.1","metadata":{"execution":{"iopub.status.busy":"2021-08-11T17:28:59.209067Z","iopub.execute_input":"2021-08-11T17:28:59.209410Z","iopub.status.idle":"2021-08-11T17:28:59.377081Z","shell.execute_reply.started":"2021-08-11T17:28:59.209370Z","shell.execute_reply":"2021-08-11T17:28:59.376265Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(train_X.shape, train_y.shape)\nprint(test_X.shape, test_y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Handle imbalanced data\nfrom imblearn.over_sampling import SMOTE\n# from imblearn.under_sampling import RandomUnderSampler\n\n\noversample = SMOTE()\ntrain_X, train_y = oversample.fit_resample(train_X, train_y)\n\nprint(sum(train_y==0))\nprint(sum(train_y==1))\n# Now the class is balanced. ","metadata":{"execution":{"iopub.status.busy":"2021-08-11T17:29:02.215562Z","iopub.execute_input":"2021-08-11T17:29:02.215939Z","iopub.status.idle":"2021-08-11T17:29:02.999872Z","shell.execute_reply.started":"2021-08-11T17:29:02.215905Z","shell.execute_reply":"2021-08-11T17:29:02.998870Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"199014\n199014\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Synthetic Minority Oversampling Technique\n\nReference: https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/","metadata":{}},{"cell_type":"markdown","source":"# Build model\n\n1. logistic regression\n2. KNN\n3. SVM","metadata":{}},{"cell_type":"code","source":"# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import cross_val_predict\n# from sklearn.model_selection import cross_val_score\n\n# # Classifier Libraries\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.svm import SVC\n# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.tree import DecisionTreeClassifier\n\n\n# classifiers = {\n#     \"LogisiticRegression\": LogisticRegression(),\n#     \"KNearest\": KNeighborsClassifier(),\n# #     \"Support Vector Classifier\": SVC(),\n# #     \"DecisionTreeClassifier\": DecisionTreeClassifier()\n# }\n\n\n# for _, classifier in classifiers.items():\n#     classifier.fit(train_X, train_y)\n#     accuracy = cross_val_score(classifier, train_X, train_y, cv=5)\n#     print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(accuracy.mean(), 2) * 100, \"% accuracy score\")\n#     pred = cross_val_predict(classifier, train_X, train_y, cv=5) #,\n#                              #method=\"decision_function\")\n#     print(classifier.__class__.__name__, roc_auc_score(train_y, pred))\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:14:47.889678Z","iopub.execute_input":"2021-08-11T16:14:47.889993Z","iopub.status.idle":"2021-08-11T16:14:47.895944Z","shell.execute_reply.started":"2021-08-11T16:14:47.889963Z","shell.execute_reply":"2021-08-11T16:14:47.894441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvm_model = SVC()\nfrom sklearn.model_selection import GridSearchCV\nsvm_hyparam = {\"C\": np.arange(1,5), \"kernel\":[\"linear\", \"rbf\"]}\nsvm_cv_model = GridSearchCV(svm_model, svm_hyparam, cv=5).fit(train_X, train_y)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T16:24:06.037602Z","iopub.execute_input":"2021-08-11T16:24:06.038037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_cv_model.best_score_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_param = svm_cv_model.best_params_\nprint(best_param)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\n\n# predict the result \n# svm = SVC(C = best_params['C'], kernel=best_params['kernel'], probability=True).fit(train_X, train_y)\nsvm = SVC(C = 3, kernel='rbf', probability=True).fit(train_X, train_y)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T17:30:05.947271Z","iopub.execute_input":"2021-08-11T17:30:05.947730Z","iopub.status.idle":"2021-08-11T20:45:12.818278Z","shell.execute_reply.started":"2021-08-11T17:30:05.947681Z","shell.execute_reply":"2021-08-11T20:45:12.815312Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"svm_y_predict = svm.predict(test_X)\nprint('accuracy_score', accuracy_score(y_test, svm_y_predict))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T20:45:12.821847Z","iopub.execute_input":"2021-08-11T20:45:12.822267Z","iopub.status.idle":"2021-08-11T20:47:57.757197Z","shell.execute_reply.started":"2021-08-11T20:45:12.822213Z","shell.execute_reply":"2021-08-11T20:47:57.754554Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-7ec97fe67351>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msvm_y_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_y_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"],"ename":"NameError","evalue":"name 'accuracy_score' is not defined","output_type":"error"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint('accuracy_score', accuracy_score(test_y, svm_y_predict))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T21:03:38.685614Z","iopub.execute_input":"2021-08-11T21:03:38.685958Z","iopub.status.idle":"2021-08-11T21:03:38.704576Z","shell.execute_reply.started":"2021-08-11T21:03:38.685929Z","shell.execute_reply":"2021-08-11T21:03:38.703694Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"accuracy_score 0.9830413257961448\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(test_y, svm_y_predict))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T21:03:42.539157Z","iopub.execute_input":"2021-08-11T21:03:42.539504Z","iopub.status.idle":"2021-08-11T21:03:42.678594Z","shell.execute_reply.started":"2021-08-11T21:03:42.539474Z","shell.execute_reply":"2021-08-11T21:03:42.677396Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      0.98      0.99     85301\n           1       0.08      0.85      0.14       142\n\n    accuracy                           0.98     85443\n   macro avg       0.54      0.92      0.57     85443\nweighted avg       1.00      0.98      0.99     85443\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Logistc Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog_hyparam={\"C\":np.logspace(-5,5,6), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\nlog=LogisticRegression()\nlog_cv=GridSearchCV(logreg,log_hyparam,cv=10)\nlog_cv.fit(train_X,train_y)\n\nprint(log_cv.best_params_)\nprint(\"accuracy \",log_cv.best_score_)\nbest_param = log_cv.best_params_\n","metadata":{"execution":{"iopub.status.busy":"2021-08-11T20:47:57.759505Z","iopub.status.idle":"2021-08-11T20:47:57.759894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log = LogisticRegression(C = best_params['C'], penalty=best_params['penalty'], probability=True).fit(train_X, train_y)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T20:47:57.760779Z","iopub.status.idle":"2021-08-11T20:47:57.761123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlog_y_predict = log.predict(test_X)\nprint('accuracy_score', accuracy_score(y_test, log_y_predict))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T20:47:57.762115Z","iopub.status.idle":"2021-08-11T20:47:57.762469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(test_y, log_y_predict))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T20:47:57.763394Z","iopub.status.idle":"2021-08-11T20:47:57.763799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_hyparam={\"n_neighbors\":[2,4,6,8,10], \"metric\":[\"euclidean\", \"manhattan\"]}\nKNN=KNeighborsClassifier()\nKNN_cv=GridSearchCV(KNN,KNN_hyparam,cv=10)\nKNN_cv.fit(train_X,train_y)\n\nprint(KNN_cv.best_params_)\nprint(\"accuracy \",KNN_cv.best_score_)\nbest_param = log_cv.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-08-11T20:47:57.764796Z","iopub.status.idle":"2021-08-11T20:47:57.765145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN = LogisticRegression(n_neighbors = best_params['n_neighbors'], metric=best_params['metric'], probability=True).fit(train_X, train_y)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T20:47:57.765978Z","iopub.status.idle":"2021-08-11T20:47:57.766402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN_y_predict = KNN.predict(test_X)\nprint('accuracy_score', accuracy_score(y_test, KNN_y_predict))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T20:47:57.767385Z","iopub.status.idle":"2021-08-11T20:47:57.767775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(test_y, KNN_y_predict))","metadata":{"execution":{"iopub.status.busy":"2021-08-11T20:47:57.769428Z","iopub.status.idle":"2021-08-11T20:47:57.769816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reference: \n1. https://www.kaggle.com/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets\n\n2. https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html","metadata":{}}]}
